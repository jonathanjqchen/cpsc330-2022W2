{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](../img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Lecture 9: Classification Metrics\n",
    "-----------\n",
    "\n",
    "UBC 2022-23 W2\n",
    "\n",
    "Instructor: Amir Abdi\n",
    " - Office Hours: Mondays 5-6 (or 5-7 if student turn-out was high)\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please share your Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img_aa/qr-code-feedback-Amir.png\" height=\"300\" width=\"300\"> \n",
    "\n",
    "https://forms.gle/NLKCe3BrLC6tLpkE8\n",
    "\n",
    "It's 100% **anonymous**\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Announcements\n",
    "\n",
    "- HW4 is due Feb 10, 11:59pm\n",
    "- Midterm Feb 15 Wednesday\n",
    "- Please make use of **OH** and **tutorials** to ask your questions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Learning outcomes \n",
    "\n",
    "From this lecture, students are expected to be able to:\n",
    "\n",
    "- Explain why accuracy is not always the best metric in ML.\n",
    "- Explain components of a **confusion matrix**. \n",
    "- Define **precision**, **recall**, and **f1-score** and use them to evaluate different classifiers. \n",
    "- Broadly explain macro-average, weighted average.\n",
    "- Interpret and use precision-recall curves. \n",
    "- Explain average precision score.\n",
    "- Interpret and use ROC curves and ROC AUC using `scikit-learn`.  \n",
    "- Identify whether there is class imbalance and whether you need to deal with it.\n",
    "- Explain and use `class_weight` to deal with data imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legends\n",
    "\n",
    "    \n",
    "| <img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f8/This_is_the_photo_of_Arthur_Samuel.jpg\" width=\"100\"> | <img src=\"http://www.cs.cmu.edu/~tom/TomHead2-6-22-22.jpg\" width=\"100\">  | <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/49/John_McCarthy_Stanford.jpg\" width=\"100\"> | <img src=\"https://datascience.columbia.edu/wp-content/uploads/2020/08/Vapnik_web.png\" width=\"100\"> | <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/a1/Alan_Turing_Aged_16.jpg\" width=\"100\"> | <img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1e/Yoshua_Bengio_2019_cropped.jpg\" width=\"100\"> |\n",
    "| :-----------: | :-----------: | :-----------: | :-----------: | :-----------: | :-----------: | \n",
    "| Arthur Samuel       | Tom Mitchell       |John McCarthy|  Vladimir N. Vapnik | Alan Turing | Yoshua Bengio |\n",
    "| (1901-1990)    | 1951 - Now       |  1927 – 2011 | 1936 - Now | 1912 – 1954 | 1964-Now |\n",
    "| First computer learning program | 1997 ML Texbook, CMU Prof | Co-coined term AI, Lisp,<br> Time-sharing, Garbage collection | SVM | Turing Test, Turning Machine | Turing Award<br> Father of Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation (Evaluation metrics for binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../code/.\")\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# Changing global matplotlib settings for confusion matrix.\n",
    "plt.rcParams[\"xtick.labelsize\"] = 18\n",
    "plt.rcParams[\"ytick.labelsize\"] = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Dataset for demonstration \n",
    "\n",
    "- Let's classify fraudulent and non-fraudulent transactions using Kaggle's [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud) data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>BALANCE</th>\n",
       "      <th>BALANCE_FREQUENCY</th>\n",
       "      <th>PURCHASES</th>\n",
       "      <th>ONEOFF_PURCHASES</th>\n",
       "      <th>INSTALLMENTS_PURCHASES</th>\n",
       "      <th>CASH_ADVANCE</th>\n",
       "      <th>PURCHASES_FREQUENCY</th>\n",
       "      <th>ONEOFF_PURCHASES_FREQUENCY</th>\n",
       "      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_TRX</th>\n",
       "      <th>PURCHASES_TRX</th>\n",
       "      <th>CREDIT_LIMIT</th>\n",
       "      <th>PAYMENTS</th>\n",
       "      <th>MINIMUM_PAYMENTS</th>\n",
       "      <th>PRC_FULL_PAYMENT</th>\n",
       "      <th>TENURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>C13605</td>\n",
       "      <td>43.775427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>523.64</td>\n",
       "      <td>523.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>492.097703</td>\n",
       "      <td>172.889643</td>\n",
       "      <td>0.75</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>C16178</td>\n",
       "      <td>2136.215769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1846.03</td>\n",
       "      <td>507.32</td>\n",
       "      <td>1338.71</td>\n",
       "      <td>187.819777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>1082.359360</td>\n",
       "      <td>521.999553</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>C10198</td>\n",
       "      <td>189.687964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.14</td>\n",
       "      <td>66.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>C18968</td>\n",
       "      <td>45.645815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>222.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>175.938042</td>\n",
       "      <td>176.481806</td>\n",
       "      <td>0.30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>C10667</td>\n",
       "      <td>3725.636832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>516.029064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1221.274221</td>\n",
       "      <td>1537.255049</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CUST_ID      BALANCE  BALANCE_FREQUENCY  PURCHASES  ONEOFF_PURCHASES  \\\n",
       "3506  C13605    43.775427                1.0     523.64            523.64   \n",
       "6009  C16178  2136.215769                1.0    1846.03            507.32   \n",
       "191   C10198   189.687964                1.0      66.14             66.14   \n",
       "8731  C18968    45.645815                1.0     222.00              0.00   \n",
       "641   C10667  3725.636832                1.0       0.00              0.00   \n",
       "\n",
       "      INSTALLMENTS_PURCHASES  CASH_ADVANCE  PURCHASES_FREQUENCY  \\\n",
       "3506                    0.00      0.000000             1.000000   \n",
       "6009                 1338.71    187.819777             1.000000   \n",
       "191                     0.00      0.000000             0.083333   \n",
       "8731                  222.00      0.000000             1.000000   \n",
       "641                     0.00    516.029064             0.000000   \n",
       "\n",
       "      ONEOFF_PURCHASES_FREQUENCY  PURCHASES_INSTALLMENTS_FREQUENCY  \\\n",
       "3506                    1.000000                          0.000000   \n",
       "6009                    0.333333                          1.000000   \n",
       "191                     0.083333                          0.000000   \n",
       "8731                    0.000000                          0.916667   \n",
       "641                     0.000000                          0.000000   \n",
       "\n",
       "      CASH_ADVANCE_FREQUENCY  CASH_ADVANCE_TRX  PURCHASES_TRX  CREDIT_LIMIT  \\\n",
       "3506                0.000000                 0             15        6500.0   \n",
       "6009                0.083333                 1             33        4500.0   \n",
       "191                 0.000000                 0              2        6000.0   \n",
       "8731                0.000000                 0             12        1500.0   \n",
       "641                 0.666667                 9              0        4000.0   \n",
       "\n",
       "         PAYMENTS  MINIMUM_PAYMENTS  PRC_FULL_PAYMENT  TENURE  \n",
       "3506   492.097703        172.889643              0.75      12  \n",
       "6009  1082.359360        521.999553              0.00      12  \n",
       "191      0.000000               NaN              0.00      12  \n",
       "8731   175.938042        176.481806              0.30      12  \n",
       "641   1221.274221       1537.255049              0.00      12  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_df = pd.read_csv(\"../data/creditcard.csv\", encoding=\"latin-1\")\n",
    "train_df, test_df = train_test_split(cc_df, test_size=0.3, random_state=111)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6265, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Good size dataset (almost a **real-world** dataset!)\n",
    "- For confidentially reasons, it only provides **transformed features with PCA** and **annonymized**, \n",
    "  - PCA is a popular dimensionality reduction technique [learn more here](https://en.wikipedia.org/wiki/Principal_component_analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6265 entries, 3506 to 4820\n",
      "Data columns (total 18 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   CUST_ID                           6265 non-null   object \n",
      " 1   BALANCE                           6265 non-null   float64\n",
      " 2   BALANCE_FREQUENCY                 6265 non-null   float64\n",
      " 3   PURCHASES                         6265 non-null   float64\n",
      " 4   ONEOFF_PURCHASES                  6265 non-null   float64\n",
      " 5   INSTALLMENTS_PURCHASES            6265 non-null   float64\n",
      " 6   CASH_ADVANCE                      6265 non-null   float64\n",
      " 7   PURCHASES_FREQUENCY               6265 non-null   float64\n",
      " 8   ONEOFF_PURCHASES_FREQUENCY        6265 non-null   float64\n",
      " 9   PURCHASES_INSTALLMENTS_FREQUENCY  6265 non-null   float64\n",
      " 10  CASH_ADVANCE_FREQUENCY            6265 non-null   float64\n",
      " 11  CASH_ADVANCE_TRX                  6265 non-null   int64  \n",
      " 12  PURCHASES_TRX                     6265 non-null   int64  \n",
      " 13  CREDIT_LIMIT                      6264 non-null   float64\n",
      " 14  PAYMENTS                          6265 non-null   float64\n",
      " 15  MINIMUM_PAYMENTS                  6041 non-null   float64\n",
      " 16  PRC_FULL_PAYMENT                  6265 non-null   float64\n",
      " 17  TENURE                            6265 non-null   int64  \n",
      "dtypes: float64(14), int64(3), object(1)\n",
      "memory usage: 930.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>BALANCE</th>\n",
       "      <th>BALANCE_FREQUENCY</th>\n",
       "      <th>PURCHASES</th>\n",
       "      <th>ONEOFF_PURCHASES</th>\n",
       "      <th>INSTALLMENTS_PURCHASES</th>\n",
       "      <th>CASH_ADVANCE</th>\n",
       "      <th>PURCHASES_FREQUENCY</th>\n",
       "      <th>ONEOFF_PURCHASES_FREQUENCY</th>\n",
       "      <th>PURCHASES_INSTALLMENTS_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_FREQUENCY</th>\n",
       "      <th>CASH_ADVANCE_TRX</th>\n",
       "      <th>PURCHASES_TRX</th>\n",
       "      <th>CREDIT_LIMIT</th>\n",
       "      <th>PAYMENTS</th>\n",
       "      <th>MINIMUM_PAYMENTS</th>\n",
       "      <th>PRC_FULL_PAYMENT</th>\n",
       "      <th>TENURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6265</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6264.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6041.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "      <td>6265.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>C13605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1591.810269</td>\n",
       "      <td>0.877991</td>\n",
       "      <td>1004.292776</td>\n",
       "      <td>594.034843</td>\n",
       "      <td>410.610045</td>\n",
       "      <td>993.864809</td>\n",
       "      <td>0.486502</td>\n",
       "      <td>0.203524</td>\n",
       "      <td>0.360645</td>\n",
       "      <td>0.138125</td>\n",
       "      <td>3.329928</td>\n",
       "      <td>14.809258</td>\n",
       "      <td>4539.618301</td>\n",
       "      <td>1738.120826</td>\n",
       "      <td>854.839446</td>\n",
       "      <td>0.147283</td>\n",
       "      <td>11.528970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2108.567361</td>\n",
       "      <td>0.236736</td>\n",
       "      <td>2170.896978</td>\n",
       "      <td>1688.960465</td>\n",
       "      <td>938.128082</td>\n",
       "      <td>2114.900417</td>\n",
       "      <td>0.401634</td>\n",
       "      <td>0.298425</td>\n",
       "      <td>0.397362</td>\n",
       "      <td>0.202488</td>\n",
       "      <td>6.869020</td>\n",
       "      <td>25.338296</td>\n",
       "      <td>3675.567078</td>\n",
       "      <td>2960.784208</td>\n",
       "      <td>2257.960099</td>\n",
       "      <td>0.286918</td>\n",
       "      <td>1.321366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>134.613205</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>384.218293</td>\n",
       "      <td>169.800871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>897.877807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>864.078680</td>\n",
       "      <td>316.469656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2101.047620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1123.580000</td>\n",
       "      <td>594.700000</td>\n",
       "      <td>462.860000</td>\n",
       "      <td>1148.569187</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6500.000000</td>\n",
       "      <td>1907.282354</td>\n",
       "      <td>826.564660</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18495.558550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49039.570000</td>\n",
       "      <td>40761.250000</td>\n",
       "      <td>22500.000000</td>\n",
       "      <td>47137.211760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>50721.483360</td>\n",
       "      <td>61031.618600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUST_ID       BALANCE  BALANCE_FREQUENCY     PURCHASES  \\\n",
       "count     6265   6265.000000        6265.000000   6265.000000   \n",
       "unique    6265           NaN                NaN           NaN   \n",
       "top     C13605           NaN                NaN           NaN   \n",
       "freq         1           NaN                NaN           NaN   \n",
       "mean       NaN   1591.810269           0.877991   1004.292776   \n",
       "std        NaN   2108.567361           0.236736   2170.896978   \n",
       "min        NaN      0.000000           0.000000      0.000000   \n",
       "25%        NaN    134.613205           0.900000     39.000000   \n",
       "50%        NaN    897.877807           1.000000    360.000000   \n",
       "75%        NaN   2101.047620           1.000000   1123.580000   \n",
       "max        NaN  18495.558550           1.000000  49039.570000   \n",
       "\n",
       "        ONEOFF_PURCHASES  INSTALLMENTS_PURCHASES  CASH_ADVANCE  \\\n",
       "count        6265.000000             6265.000000   6265.000000   \n",
       "unique               NaN                     NaN           NaN   \n",
       "top                  NaN                     NaN           NaN   \n",
       "freq                 NaN                     NaN           NaN   \n",
       "mean          594.034843              410.610045    993.864809   \n",
       "std          1688.960465              938.128082   2114.900417   \n",
       "min             0.000000                0.000000      0.000000   \n",
       "25%             0.000000                0.000000      0.000000   \n",
       "50%            45.000000               85.000000      0.000000   \n",
       "75%           594.700000              462.860000   1148.569187   \n",
       "max         40761.250000            22500.000000  47137.211760   \n",
       "\n",
       "        PURCHASES_FREQUENCY  ONEOFF_PURCHASES_FREQUENCY  \\\n",
       "count           6265.000000                 6265.000000   \n",
       "unique                  NaN                         NaN   \n",
       "top                     NaN                         NaN   \n",
       "freq                    NaN                         NaN   \n",
       "mean               0.486502                    0.203524   \n",
       "std                0.401634                    0.298425   \n",
       "min                0.000000                    0.000000   \n",
       "25%                0.083333                    0.000000   \n",
       "50%                0.500000                    0.083333   \n",
       "75%                0.916667                    0.333333   \n",
       "max                1.000000                    1.000000   \n",
       "\n",
       "        PURCHASES_INSTALLMENTS_FREQUENCY  CASH_ADVANCE_FREQUENCY  \\\n",
       "count                        6265.000000             6265.000000   \n",
       "unique                               NaN                     NaN   \n",
       "top                                  NaN                     NaN   \n",
       "freq                                 NaN                     NaN   \n",
       "mean                            0.360645                0.138125   \n",
       "std                             0.397362                0.202488   \n",
       "min                             0.000000                0.000000   \n",
       "25%                             0.000000                0.000000   \n",
       "50%                             0.166667                0.000000   \n",
       "75%                             0.750000                0.250000   \n",
       "max                             1.000000                1.500000   \n",
       "\n",
       "        CASH_ADVANCE_TRX  PURCHASES_TRX  CREDIT_LIMIT      PAYMENTS  \\\n",
       "count        6265.000000    6265.000000   6264.000000   6265.000000   \n",
       "unique               NaN            NaN           NaN           NaN   \n",
       "top                  NaN            NaN           NaN           NaN   \n",
       "freq                 NaN            NaN           NaN           NaN   \n",
       "mean            3.329928      14.809258   4539.618301   1738.120826   \n",
       "std             6.869020      25.338296   3675.567078   2960.784208   \n",
       "min             0.000000       0.000000    150.000000      0.000000   \n",
       "25%             0.000000       1.000000   1700.000000    384.218293   \n",
       "50%             0.000000       7.000000   3000.000000    864.078680   \n",
       "75%             4.000000      17.000000   6500.000000   1907.282354   \n",
       "max           123.000000     358.000000  30000.000000  50721.483360   \n",
       "\n",
       "        MINIMUM_PAYMENTS  PRC_FULL_PAYMENT       TENURE  \n",
       "count        6041.000000       6265.000000  6265.000000  \n",
       "unique               NaN               NaN          NaN  \n",
       "top                  NaN               NaN          NaN  \n",
       "freq                 NaN               NaN          NaN  \n",
       "mean          854.839446          0.147283    11.528970  \n",
       "std          2257.960099          0.286918     1.321366  \n",
       "min             0.019163          0.000000     6.000000  \n",
       "25%           169.800871          0.000000    12.000000  \n",
       "50%           316.469656          0.000000    12.000000  \n",
       "75%           826.564660          0.125000    12.000000  \n",
       "max         61031.618600          1.000000    12.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- We do not have categorical features. **All features are numeric**. \n",
    "- We have to be careful about the `Time` and `Amount` features. \n",
    "- We could scale `Amount`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do we want to scale **time**?\n",
    "- What does **time** tell us about the sample?\n",
    "  - Could some fradulent activities happen at the same time (temporal correlation)?\n",
    "  - Could fradulent activities today tell us something about fradulent activities in the future?\n",
    "  \n",
    "For now, in this lecture, we will drop **time**; later on, in another lecture, we will focus more on **time** as a feature in time-series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's separate `X` and `y` for train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Class', 'Time'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_big, y_train_big \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, train_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m\"\u001b[39m]), test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/frame.py:5396\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5248\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5257\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5260\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5261\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5394\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5395\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5398\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/indexes/base.py:6977\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6976\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6977\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6978\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Class', 'Time'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X_train_big, y_train_big = train_df.drop(columns=[\"Class\", \"Time\"]), train_df[\"Class\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"Class\", \"Time\"]), test_df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- It's easier to demonstrate evaluation metrics using an **explicit validation** set instead of using cross-validation. \n",
    "- And we have **enough data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/train-valid-test-split.png' width=\"1500\" height=\"1500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_big' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_valid, y_train, y_valid \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mX_train_big\u001b[49m, y_train_big, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_big' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_big, y_train_big, test_size=0.3, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baseline: DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_valid, y_valid) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Observations \n",
    "\n",
    "- `DummyClassifier` is getting **0.998 ACCURACY on validation set**!! \n",
    "- Should we be happy with this accuracy and deploy this `DummyClassifier` model for fraud detection? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "What's the class distribution? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We have **class imbalance**. \n",
    "  - We have **MANY non-fraud transactions** and **only a handful of fraud transactions**. \n",
    "- So in the training set, `most_frequent` strategy is labeling 199,025 (99.83%) instances correctly and only 339 (0.17%) instances incorrectly. \n",
    "- Is this what we want? \n",
    "- The \"fraud\" class is the important class that we want to spot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "-----------------\n",
    "Let's scale the features and try `LogisticRegression`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_valid, y_valid) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- We are getting a slightly better score with logistic regression.  \n",
    "- What score should be considered an acceptable score here? \n",
    "- Are we actually spotting any \"fraud\" transactions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `.score` in **Classification** by default returns **ACCURACY** which is \n",
    "$$\\text{accuracy} = \\frac{\\text{correct predictions}}{\\text{total examples}}$$\n",
    "- Is accuracy a good metric here? \n",
    "- Is there anything more informative than accuracy that we can use here? \n",
    "\n",
    "Let's dig a little deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One way to get a better understanding of the errors is by looking at \n",
    "- false positives (type I errors), where the model incorrectly spots examples as fraud\n",
    "- false negatives (type II errors), where it's missing to spot fraud examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# --------- New Code ---------------\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    display_labels=[\"Non fraud\", \"fraud\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    "    colorbar=False,\n",
    ");\n",
    "# --------- New Code ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare that with the Confusion Matrix of Dummy Clasifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    dummy,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    display_labels=[\"Non fraud\", \"fraud\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    "    colorbar=False,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from plotting_functions import plot_confusion_matrix_example\n",
    "\n",
    "predictions = pipe.predict(X_valid)\n",
    "TN, FP, FN, TP = confusion_matrix(y_valid, predictions).ravel()\n",
    "plot_confusion_matrix_example(TN, FP, FN, TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Perfect prediction has all values down the diagonal\n",
    "- Off diagonal entries can often tell us about what is being mis-predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is \"positive\" and \"negative\"?\n",
    "\n",
    "- Two kinds of binary classification problems \n",
    "    - Distinguishing between two classes\n",
    "    - Spotting a class (spot fraud transaction, spot spam, spot disease)\n",
    "- In case of spotting problems, the thing that we are interested in spotting is considered \"positive\". \n",
    "- Above we wanted to **spot (detect) fraudulent transactions** and so **Fraudulents are \"positive\"**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can get a numpy array of confusion matrix as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = pipe.predict(X_valid)\n",
    "TN, FP, FN, TP = confusion_matrix(y_valid, predictions).ravel()\n",
    "print(\"Confusion matrix for fraud data set\")\n",
    "print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "[Read for yourself at home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confusion matrix with cross-validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- You can also calculate confusion matrix with cross-validation using the `cross_val_predict` method.  \n",
    "- But then you cannot conveniently use `plot_confusion_matrix`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "confusion_matrix(y_train, cross_val_predict(pipe, X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[end of Read for yourself at home\n",
    "\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Precision, recall, f1 score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- We have been using `.score` to assess our models, which returns **ACCURACY** by default. \n",
    "- Accuracy is misleading when we have class imbalance.\n",
    "- We need other metrics to assess our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We'll discuss three commonly used metrics which are based on confusion matrix: \n",
    "    - recall\n",
    "    - precision\n",
    "    - f1 score \n",
    "- Later we'll talk about a few ways to address class imbalance problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "predictions = pipe_lr.predict(X_valid)\n",
    "TN, FP, FN, TP = confusion_matrix(y_valid, predictions).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with ACCURACY:\n",
    "\n",
    "$$ accuracy = \\frac{TP+TN}{all} = \\frac{TP+TN}{TP+TN+FP+FN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision \n",
    "\n",
    "Among the positive examples you identified, how many were actually positive?\n",
    "\n",
    "$$ precision = \\frac{TP}{TP+FP} = \\frac{TP}{\\#detected\\_positives} $$\n",
    "\n",
    "------\n",
    "Precision captures the **Quality** of detection\n",
    "- from detected ones, how many are correct?\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    display_labels=[\"Non fraud\", \"fraud\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TP = %0.4f, FP = %0.4f\" % (TP, FP))\n",
    "precision = TP / (TP + FP)\n",
    "print(\"Precision: %0.4f\" % (precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall \n",
    "\n",
    "Among all positive examples, how many did you identify?\n",
    "$$ recall = \\frac{TP}{TP+FN} = \\frac{TP}{\\#actual\\_positives} $$\n",
    "\n",
    "------\n",
    "Recall captures the **Quantity** of detecting positives\n",
    "- How many of the total positives have we detected?\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    display_labels=[\"Non fraud\", \"fraud\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TP = %0.4f, FN = %0.4f\" % (TP, FN))\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Recall: %0.4f\" % (recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### F1-score\n",
    "\n",
    "- F1-score combines precision and recall to give one score, which could be used in hyperparameter optimization, for instance. \n",
    "- F1-score is a **harmonic mean** of precision and recall.\n",
    "\n",
    "\n",
    "$$ f1 = 2 \\times \\frac{ precision \\times recall}{precision + recall}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"precision: %0.4f\" % (precision))\n",
    "print(\"recall: %0.4f\" % (recall))\n",
    "f1_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"f1: %0.4f\" % (f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at all metrics at once on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## Calculate evaluation metrics by ourselves\n",
    "data = {\n",
    "    \"calculation\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"error\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1 score\": [],\n",
    "}\n",
    "data[\"calculation\"].append(\"manual\")\n",
    "data[\"accuracy\"].append((TP + TN) / (TN + FP + FN + TP))\n",
    "data[\"error\"].append((FP + FN) / (TN + FP + FN + TP))\n",
    "data[\"precision\"].append(precision)  # TP / (TP + FP)\n",
    "data[\"recall\"].append(recall)  # TP / (TP + FN)\n",
    "data[\"f1 score\"].append(f1_score)  # (2 * precision * recall) / (precision + recall)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `scikit-learn` has functions for [these metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "data[\"accuracy\"].append(accuracy_score(y_valid, pipe_lr.predict(X_valid)))\n",
    "data[\"error\"].append(1 - accuracy_score(y_valid, pipe_lr.predict(X_valid)))\n",
    "data[\"precision\"].append(\n",
    "    precision_score(y_valid, pipe_lr.predict(X_valid), zero_division=1)\n",
    ")\n",
    "data[\"recall\"].append(recall_score(y_valid, pipe_lr.predict(X_valid)))\n",
    "data[\"f1 score\"].append(f1_score(y_valid, pipe_lr.predict(X_valid)))\n",
    "data[\"calculation\"].append(\"sklearn\")\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index([\"calculation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores match, of course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `classification_report` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a convenient function called `classification_report` in `sklearn` which gives this info. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_valid, pipe_lr.predict(X_valid), target_names=[\"non-fraud\", \"fraud\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️⚠️⚠️ The \"rounding to 2 precision points\" has resulted in some 1.00 in the above table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "**[study for yourself at home]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Macro average\n",
    "\n",
    "- You give equal importance to all classes and average over all classes.  \n",
    "- For instance, in the example above, recall for non-fraud is 1.0 and fraud is 0.63, and so macro average is 0.81. \n",
    "- More relevant in case of multi-class problems.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Weighted average\n",
    "\n",
    "- Weighted by the number of samples in each class. \n",
    "- Divide by the total number of samples. \n",
    "\n",
    "Which one is relevant when depends upon whether you think each class should have the same weight or each sample should have the same weight. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 0, 1, 0]\n",
    "y_pred = [0, 0, 0, 1, 0]\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weighted average is weighted by the proportion of examples in a particular class. So for the toy example above:\n",
    "- weighted_average precision: 3/5 * 0.75 + 2/5 * 1.00 = 0.85\n",
    "- weighted_average recall: 3/5 * 1.00 + 2/5 * 0.5 = 0.80\n",
    "- weighted_average f1-score: 3/5 * 0.86 + 2/5 * 0.67 = 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- macro average gives equal weight to both classes. So for the toy example above:\n",
    "- macro average precision: 0.5 * 0.75 + 0.5 * 1.00 =0. 875\n",
    "- macro average recall: 0.5 * 1.00 + 0.5 * 0.5 =0. 75\n",
    "- macro average f1-score: 0.5 * 0.75 + 0.5 * 1.00 =0.765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[study for yourself at home]**\n",
    "\n",
    "----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interim summary \n",
    "\n",
    "- Accuracy is misleading when you have class imbalance. \n",
    "- A confusion matrix provides a way to break down errors made by our model. \n",
    "- We looked at three metrics based on confusion matrix: \n",
    "    - precision, recall, f1-score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Note that in **Binary Classification**, what you consider **\"positive\"** (e.g. fraud in our case) is important when calculating precision, recall, and f1-score. \n",
    "  - If you flip what is considered positive or negative, we'll end up with different TP, FP, TN, FN, and hence different precision, recall, and f1-scores. \n",
    "\n",
    "\n",
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evalution metrics overview  \n",
    "There is a lot of terminology here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='../img/evaluation-metrics.png' width=\"1000\" height=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `cross_validate` with different metrics\n",
    "\n",
    "We can pass different evaluation metrics with `scoring` argument of `cross_validate`.\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# ------ New code -----------------\n",
    "scores = cross_validate(\n",
    "    pipe, X_train_big, y_train_big, return_train_score=True, scoring=[\"accuracy\", \"f1\", \"recall\", \"precision\"]\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- You can also create [your own scoring function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) and pass it to `cross_validate`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### (iClicker) Exercise 9.1 \n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/EMMJ**\n",
    "\n",
    "**Select all of the following statements which are TRUE.**\n",
    "\n",
    "- (A) In medical diagnosis, false positives are likely to be more damaging than false negatives (assume \"positive\" means the person has a disease, \"negative\" means they are healthy).\n",
    "- (B) In spam classification, false positives are more damaging than false negatives (assume \"positive\" means the email is spam, \"negative\" means it's not).\n",
    "- (C) If method A gets a higher accuracy than method B, that means its precision is also higher.\n",
    "- (D) If method A gets a higher accuracy than method B, that means its recall is also higher.\n",
    "\n",
    "\n",
    "Answers: B ,  (A is debatable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img_aa/medical_fp_vs_fn.png' width=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Method A - higher accuracy but lower precision\n",
    "\n",
    "| Negative | Positive\n",
    "| -------- |:-------------:|\n",
    "| 90      | 5|\n",
    "| 5      | 0|\n",
    "\n",
    "Method B - lower accuracy but higher precision\n",
    "\n",
    "| Negative | Positive\n",
    "| -------- |:-------------:|\n",
    "| 80      | 15|\n",
    "| 0      | 5|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Precision-Recall curve / ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Confusion matrix provides a detailed break down of the errors made by the model. \n",
    "- But when creating a confusion matrix, we are using \"hard\" predictions. \n",
    "- Most classifiers in `scikit-learn` provide **`predict_proba` method (or `decision_function`) which provides degree of certainty about predictions** by the classifier. \n",
    "- Can we explore the degree of uncertainty to understand and improve the model performance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's revisit the classification report on our fraud detection example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe_lr.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pipe_lr.predict(X_valid)\n",
    "print(classification_report(y_valid, y_pred, target_names=[\"non-fraud\", \"fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**By default, predictions use the threshold of 0.5. If `predict_proba` > 0.5, predict \"fraud\" else predict \"non-fraud\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ------- New Code -------------------\n",
    "# pipe_lr.predict(X_valid) --> original\n",
    "y_pred = pipe_lr.predict_proba(X_valid)[:, 1] > 0.50\n",
    "# ------------------------------------\n",
    "print(classification_report(y_valid, y_pred, target_names=[\"non-fraud\", \"fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Suppose for your business it is more costly to miss fraudulent transactions and you want to achieve a recall of at least 75% for the \"fraud\" class. \n",
    "- One way to do this is by changing the threshold of `predict_proba`.\n",
    "    - `predict` returns 1 when `predict_proba`'s probabilities are above 0.5 for the \"fraud\" class.\n",
    "\n",
    "**Key idea: what if we threshold the probability at a smaller value so that we identify more examples as \"fraud\" examples?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's lower the threshold to **0.1**   \n",
    "In other words, predict the examples as \"fraud\" if `predict_proba` > 0.1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold = pipe_lr.predict_proba(X_valid)[:, 1] > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_valid, y_pred_lower_threshold, target_names=[\"non-fraud\", \"fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Precision/Recall tradeoff \n",
    "\n",
    "- But there is a trade-off between precision and recall. \n",
    "- If you identify more things as \"fraud\", recall is going to increase but there are likely to be more false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's sweep through different thresholds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.0, 1.0, 0.1)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def f(threshold):\n",
    "    preds = pipe_lr.predict_proba(X_valid)[:, 1] > threshold    \n",
    "    print(\"Threshold: \", np.round(threshold,4))\n",
    "    print(\"Precision: \", np.round(precision_score(y_valid, preds),4))\n",
    "    print(\"Recall: \", np.round(recall_score(y_valid, preds), 4))    \n",
    "    print(\"f1 score: \", np.round(f1_score(y_valid, preds), 4))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "interactive(\n",
    "    f,\n",
    "    threshold=widgets.FloatSlider(min=0, max=0.9, step=0.1, value=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view P and R for different thresholds as a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pr_dict = {\"threshold\": [], \"precision\": [], \"recall\": [], \"f1 score\": []}\n",
    "for threshold in thresholds:\n",
    "    preds = pipe_lr.predict_proba(X_valid)[:, 1] > threshold\n",
    "    pr_dict[\"threshold\"].append(threshold)\n",
    "    pr_dict[\"precision\"].append(precision_score(y_valid, preds))\n",
    "    pr_dict[\"recall\"].append(recall_score(y_valid, preds))\n",
    "    pr_dict[\"f1 score\"].append(f1_score(y_valid, preds))\n",
    "pd.DataFrame(pr_dict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decreasing the threshold\n",
    "\n",
    "- Decreasing the threshold means a lower bar for predicting fraud. \n",
    "    - You are willing to risk more false positives in exchange of more true positives. \n",
    "    - recall would either stay the same or go up and precision is likely to go down\n",
    "    - occasionally, precision may increase if all the new examples after decreasing the threshold are TPs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Increasing the threshold\n",
    "\n",
    "- Increasing the threshold means a higher bar for predicting fraud. \n",
    "    - recall would go down or stay the same but precision is likely to go up \n",
    "    - occasionally, precision may go down as the denominator for precision is TP+FP.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Operating point \n",
    "\n",
    "How to decide which threshold to use?\n",
    "- It is decided by the **operating point** of the business.\n",
    "- Setting a requirement on a classifier (e.g., recall of >= 0.75) is called setting the **operating point**. \n",
    "- It's usually driven by **business goals** and is useful to make **performance guarantees to customers**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Precision-Recall (PR) curve\n",
    "\n",
    "Often, when developing a model, it's not always clear what the operating point will be and to understand the the model better, it's informative to look at all possible thresholds and corresponding trade-offs of precision and recall in a plot.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_valid, pipe_lr.predict_proba(X_valid)[:, 1]\n",
    ")\n",
    "plt.plot(precision, recall, label=\"logistic regression: PR curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_valid, pipe_lr.predict(X_valid)),\n",
    "    recall_score(y_valid, pipe_lr.predict(X_valid)),\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Each point in the curve corresponds to a possible threshold of the `predict_proba` output. \n",
    "- We can achieve a recall of 0.8 at a precision of 0.4. \n",
    "- The red dot marks the point corresponding to the threshold 0.5.\n",
    "- **The top-most right-most point in this PR diagram would be a perfect classifier (precision = recall = 1).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The threshold is not shown here, but it's going from 0 (upper-left) to 1 (lower right).\n",
    "- At a threshold of 0 (upper left), we are classifying everything  as \"fraud\".\n",
    "- Raising the threshold increases the precision but at the expense of lowering the recall. \n",
    "- At the extreme right, where the threshold is 1, we get into the situation where all the examples classified as \"fraud\" are actually \"fraud\"; we have no false positives. \n",
    "- Here we have a high precision but lower recall. \n",
    "- Usually the goal is to **keep recall high as precision goes up**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A few comments on PR curve\n",
    "\n",
    "- Different classifiers might work well in different parts of the curve, i.e., at different operating points.   \n",
    "- We can compare PR curves of different classifiers to understand these differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Average Precision (AP) score \n",
    "\n",
    "- Often it's useful to have one number summarizing the PR plot (e.g., in hyperparameter optimization)\n",
    "- One way to do this is by **computing the area under the PR curve**. \n",
    "- This is called **average precision** (AP score)\n",
    "- AP score has a value between 0 (worst) and 1 (best). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "y_predict = pipe_lr.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "#  -------- New  Code --------------\n",
    "ap_lr = average_precision_score(y_valid, y_predict)\n",
    "# ----------------------------------\n",
    "print(\"Average precision of logistic regression: {:.3f}\".format(ap_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following handy function of `sklearn` to get the PR curve and the corresponding AP score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "#  -------- New  Code --------------\n",
    "PrecisionRecallDisplay.from_estimator(pipe_lr, X_valid, y_valid);\n",
    "# ----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AP vs. F1-score\n",
    "\n",
    "It is very important to note this distinction:\n",
    "\n",
    "- F1 score is for a given threshold and measures the quality of `predict`.\n",
    "- AP score is a summary across thresholds and measures the quality of `predict_proba`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Remember to pick the desired threshold based on the results on the validation set and **NOT** on the test set.\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br>\n",
    "For classification problems with **imbalanced classes**, using AP score is more meaningful than using accuracy. \n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A few comments on PR curve\n",
    "\n",
    "- Different classifiers might work well in different parts of the curve, i.e., at different operating points.   \n",
    "- We can compare PR curves of different classifiers to understand these differences. \n",
    "- Let's create PR curves for SVC and Logistic Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipe_svc = make_pipeline(StandardScaler(), SVC())\n",
    "pipe_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "pipe_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get precision and recall for different thresholds? \n",
    "- Use the function `precision_recall_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_lr, recall_lr, thresholds_lr = precision_recall_curve(\n",
    "    y_valid, pipe_lr.predict_proba(X_valid)[:, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "How many thresholds? \n",
    "- The number of **unique `predict_proba` scores** in our dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(pipe_lr.predict_proba(X_valid)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_lr.shape, precision_lr.shape, recall_lr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each threshold, precision and recall is calculated.  \n",
    "- The last precision and recall values are 1. and 0. respectively and do not have a corresponding threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About SVC and confidence of predictions:\n",
    "- SVC doesn't have `predict_proba`. Instead it has something called `decision_function`. \n",
    "- The index of the threshold that is closest to 0 of decision function is the default threshold in SVC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "precision_lr, recall_lr, thresholds_lr = precision_recall_curve(\n",
    "    y_valid, pipe_lr.predict_proba(X_valid)[:, 1]\n",
    ")\n",
    "precision_svc, recall_svc, thresholds_svc = precision_recall_curve(\n",
    "    y_valid, pipe_svc.decision_function(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the threhold indices which are close to zero (default threshold) in LR and SVC\n",
    "close_default_lr = np.argmin(np.abs(thresholds_lr - 0.5))\n",
    "close_zero_svm = np.argmin(np.abs(thresholds_svc))\n",
    "\n",
    "# A bit of plotting\n",
    "plt.plot(precision_svc, recall_svc, label=\"svc\")\n",
    "plt.plot(precision_lr, recall_lr, label=\"logistic regression\")\n",
    "plt.plot(\n",
    "    precision_svc[close_zero_svm],\n",
    "    recall_svc[close_zero_svm],\n",
    "    \"o\",\n",
    "    markersize=10,\n",
    "    label=\"default threshold svc\",\n",
    "    c=\"b\",\n",
    ")\n",
    "plt.plot(\n",
    "    precision_lr[close_default_lr],\n",
    "    recall_lr[close_default_lr],\n",
    "    \"*\",\n",
    "    markersize=10,\n",
    "    label=\"default threshold logistic regression\",\n",
    "    c=\"r\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "**[Study on your own]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "svc_preds = pipe_svc.predict(X_valid)\n",
    "lr_preds = pipe_lr.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"f1_score of logistic regression: {:.3f}\".format(f1_score(y_valid, lr_preds)))\n",
    "print(\"f1_score of svc: {:.3f}\".format(f1_score(y_valid, svc_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ap_lr = average_precision_score(y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
    "ap_svc = average_precision_score(y_valid, pipe_svc.decision_function(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Average precision of logistic regression: {:.3f}\".format(ap_lr))\n",
    "print(\"Average precision of SVC: {:.3f}\".format(ap_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Comparing the precision-recall curves provide us a detail insight compared to f1 score.\n",
    "- For example, F1 scores for SVC and logistic regressions are pretty similar. In fact, f1 score of logistic regression is a tiny bit better. \n",
    "- But when we look at the PR curve, we see that SVC is doing better than logistic regression for most of the other thresholds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[end of Study on your own]**\n",
    "\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Receiver Operating Characteristic (ROC) curve \n",
    "\n",
    "- Another commonly used tool to analyze the behavior of classifiers at different thresholds.  \n",
    "- Similar to PR curve, it considers all possible thresholds for a given classifier given by `predict_proba` \n",
    "  - but instead of precision and recall it plots **false positive rate (FPR)** and **true positive rate (TPR or recall)**.\n",
    "$$ TPR = \\text{recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "$$FPR  = \\frac{FP}{FP + TN}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The **ideal** curve is close to the **top-left**\n",
    "    - Ideally, you want a classifier with high recall while keeping low false positive rate.  \n",
    "- The red dot corresponds to the threshold of 0.5, which is used by predict.\n",
    "- **In this example**, we see that compared to the default threshold, **we can achieve a better recall of around 0.8 without increasing FPR**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "**[Study on your own]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's compare ROC curve of different classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "fpr_svc, tpr_svc, thresholds_svc = roc_curve(\n",
    "    y_valid, pipe_svc.decision_function(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_default_lr = np.argmin(np.abs(thresholds_lr - 0.5))\n",
    "close_zero_svm = np.argmin(np.abs(thresholds_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr_svc, tpr_svc, label=\"svc\")\n",
    "plt.plot(fpr_lr, tpr_lr, label=\"logistic regression\")\n",
    "plt.plot(\n",
    "    fpr_svc[close_zero_svm],\n",
    "    tpr_svc[close_zero_svm],\n",
    "    \"o\",\n",
    "    markersize=10,\n",
    "    label=\"default threshold svc\",\n",
    "    c=\"b\",\n",
    ")\n",
    "plt.plot(\n",
    "    fpr_lr[close_default_lr],\n",
    "    tpr_lr[close_default_lr],\n",
    "    \"*\",\n",
    "    markersize=10,\n",
    "    label=\"default threshold logistic regression\",\n",
    "    c=\"r\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate (Recall)\")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[end of Study on your own]**\n",
    "\n",
    "-----------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Area under the curve (AUC)\n",
    "\n",
    "**AUC = Area under the ROC curve**\n",
    "\n",
    "AUC provides a single meaningful number for the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_lr = roc_auc_score(y_valid, pipe_lr.predict_proba(X_valid)[:, 1])\n",
    "roc_svc = roc_auc_score(y_valid, pipe_svc.decision_function(X_valid))\n",
    "print(\"AUC for LR: {:.3f}\".format(roc_lr))\n",
    "print(\"AUC for SVC: {:.3f}\".format(roc_svc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **AUC of 0.5 means random chance**. \n",
    "  - When AUC is approximately 0.5, the model has no discrimination capacity to distinguish between positive class and negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC can be interpreted as evaluating the **ranking** of positive examples.\n",
    "- What's the probability that a randomly picked positive point has a higher score according to the classifier than a randomly picked point from the negative class. \n",
    "- AUC of 1.0 means **all positive points have a higher score than all negative points**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `PrecisionRecallCurveDisplay`, there is a `RocCurveDisplay` function in sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_estimator(pipe_lr, X_valid, y_valid);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's look at all the scores at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = [\"accuracy\", \"f1\", \"recall\", \"precision\", \"roc_auc\", \"average_precision\"]\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "scores = cross_validate(pipe, X_train_big, y_train_big, scoring=scoring)\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br><br>\n",
    "Check out [these visualization](https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation) on ROC and AUC.  \n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Precision-Recall (PR) Curve --> AP \n",
    "- Receiver Operating Characteristic (ROC) curve --> AUC\n",
    "- ROC curves should be used when there are roughly equal numbers of observations for each class.\n",
    "- Precision-Recall curves should be used when there is a **moderate to large class imbalance**.\n",
    "\n",
    "Learn more here: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dealing with class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Class imbalance in training sets\n",
    "\n",
    "- This typically refers to having many more examples of one class than another in one's training set.\n",
    "- Real world data is often imbalanced. \n",
    "    - Our Credit Card Fraud dataset is imbalanced.\n",
    "    - Ad clicking data is usually drastically imbalanced. (Only around ~0.01% ads are clicked.)\n",
    "    - Spam classification datasets are also usually imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Addressing class imbalance\n",
    "A very important question to ask yourself: \"**Why** do I have a class imbalance?\"\n",
    "\n",
    "- Is it because one class is **naturally more rare** than the other?\n",
    "- Is it because of my **data collection** methods?\n",
    "  \n",
    "In some cases, it may be fine to just ignore the class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which type of error is more important? \n",
    "\n",
    "- False positives (FPs) and false negatives (FNs) have quite different real-world consequences. \n",
    "- In PR curve and ROC curve, we saw how changing the prediction threshold can change FPs and FNs. \n",
    "- We can then pick the threshold that's appropriate for our problem. \n",
    "- Example: if we want high recall, we may use a lower threshold (e.g., a threshold of 0.1). We'll then catch more fraudulent transactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_valid)\n",
    "print(classification_report(y_valid, y_pred, target_names=[\"non-fraud\", \"fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And changing threshold to 0.10 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pipe_lr.predict_proba(X_valid)[:, 1] > 0.10\n",
    "print(classification_report(y_valid, y_pred, target_names=[\"non-fraud\", \"fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling imbalance\n",
    "\n",
    "Can we change the model itself rather than changing the threshold so that it takes into account the errors that are important to us?\n",
    "\n",
    "There are two common approaches for this: \n",
    "- **Changing the data (optional)** (not covered here)\n",
    "   - Undersampling\n",
    "   - Oversampling \n",
    "       - Random oversampling\n",
    "       - SMOTE \n",
    "- **Changing the training procedure** \n",
    "    - `class_weight`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Changing the training procedure \n",
    "\n",
    "- Most of `sklearn` classifiers have a parameter called `class_weight`.\n",
    "- This allows you to specify that one class is more important than another.\n",
    "  - For example, maybe a false negative is 10x more problematic than a false positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: `class_weight` parameter of `sklearn LogisticRegression` \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "> class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, **class_weight=None**, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "> class_weight: dict or 'balanced', default=None\n",
    "\n",
    "> Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\"\n",
    "HTML(\"<iframe src=%s width=1000 height=650></iframe>\" % url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Let's train with default parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe_lr,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    display_labels=[\"Non fraud\", \"fraud\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Let's set \"fraud\" class a weight of 10.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lr_weight = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    LogisticRegression(\n",
    "        max_iter=500, \n",
    "        class_weight={0:1, 1: 10}  # ---> notice the weights\n",
    "    )\n",
    ")\n",
    "pipe_lr_weight.fit(X_train, y_train)\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe_lr_weight,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    display_labels=[\"Non fraud\", \"fraud\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Notice we've **reduced false negatives** and predicted more Fraud this time.\n",
    "- This was equivalent to saying give 10x more \"importance\" to fraud class. \n",
    "- Note that as a consequence we are also **increasing false positives**.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `class_weight=\"balanced\"`\n",
    "- A useful setting is `class_weight=\"balanced\"`.\n",
    "- This sets the weights so that the classes are \"equal\".\n",
    "\n",
    "> class_weight: dict, ‘balanced’ or None\n",
    "\n",
    "> The “balanced” mode uses the values of y to automatically **adjust weights inversely proportional** to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).\n",
    "\n",
    "> sklearn.utils.class_weight.compute_class_weight(class_weight, classes, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lr_balanced = make_pipeline(\n",
    "    StandardScaler(), LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
    ")\n",
    "pipe_lr_balanced.fit(X_train, y_train)\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe_lr_balanced,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    display_labels=[\"Non fraud\", \"fraud\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reduced false negatives but we have many more false positives now ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Are we doing better with `class_weight=\"balanced\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dict = {}\n",
    "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression(max_iter=500))\n",
    "scoring = [\"accuracy\", \"f1\", \"recall\", \"precision\", \"roc_auc\", \"average_precision\"]\n",
    "orig_scores = cross_validate(pipe_lr, X_train_big, y_train_big, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pipe_lr_balanced = make_pipeline(\n",
    "    StandardScaler(), LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
    ")\n",
    "scoring = [\"accuracy\", \"f1\", \"recall\", \"precision\", \"roc_auc\", \"average_precision\"]\n",
    "bal_scores = cross_validate(pipe_lr_balanced, X_train_big, y_train_big, scoring=scoring)\n",
    "comp_dict = {\n",
    "    \"Original\": pd.DataFrame(orig_scores).mean().tolist(),\n",
    "    \"class_weight='balanced'\": pd.DataFrame(bal_scores).mean().tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(comp_dict, index=bal_scores.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall is much better but precision has dropped a lot; we have many false positives. \n",
    "- You could also optimize `class_weight` using hyperparameter optimization for your specific problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Changing the class weight will **generally reduce accuracy**.\n",
    "  - The original model was trying to maximize accuracy.\n",
    "  - Now you're telling it to do something different.\n",
    "- But that can be fine, **accuracy isn't the only metric that matters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "-----------\n",
    "**[Reminder: Covered before]**\n",
    "**[Re-study on your own]**\n",
    "\n",
    "### Stratified Sampling when splitting data into Train/Valid/Test\n",
    "\n",
    "- A similar idea of \"balancing\" classes can be applied to data splits.\n",
    "- We have the same option in `train_test_split` with the `stratify` argument. \n",
    "- By default it splits the data so that if we have 10% negative examples in total, then each split will have 10% negative examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stratified-sampling](https://cdn.scribbr.com/wp-content/uploads/2020/09/stratified-sample-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- If you are carrying out cross validation using `cross_validate`, by default it uses [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html). From the documentation: \n",
    "\n",
    "> This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "- In other words, if we have 10% negative examples in total, then each fold will have 10% negative examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**[End of Re-study on your own]**\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What did we learn today? \n",
    "\n",
    "- A number of possible ways to evaluate Classifiers\n",
    "    - Choose the evaluation metric that makes most sense in your context or which is most common in your discipline  \n",
    "- Two kinds of binary classification problems \n",
    "    - Distinguishing between two classes (e.g., dogs vs. cats)\n",
    "    - Spotting a class (e.g., spot fraud transaction, spot spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Precision, recall, f1-score are useful when dealing with spotting problems. \n",
    "- The thing that we are interested in spotting is considered \"positive\".   \n",
    "- Do you need to deal with class imbalance in the given problem? \n",
    "- Methods to deal with class imbalance \n",
    "    - Changing the training procedure \n",
    "        - `class_weight`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Relevant papers and resources \n",
    "\n",
    "- [The Relationship Between Precision-Recall and ROC Curves](https://www.biostat.wisc.edu/~page/rocpr.pdf)\n",
    "- [Article claiming that PR curve are better than ROC for imbalanced datasets](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118432)\n",
    "- [Precision-Recall-Gain Curves: PR Analysis Done Right](https://papers.nips.cc/paper/2015/file/33e8075e9970de0cfea955afd4644bb2-Paper.pdf)\n",
    "- [ROC animation](https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation)\n",
    "- [Generalization in Adaptive Data Analysis and Holdout Reuse](https://arxiv.org/pdf/1506.02629.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/eva-seeyou.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
